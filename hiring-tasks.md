# 招聘岗位完整描述（供 Agent 更新 SOCIAL.md 使用）

以下4个岗位的完整描述、甄选标准和面试策略，供你发给 Telegram Agent 参考。

---

## 岗位 1: 全栈 AI 工程师

- **任务 ID**: `hiring-ai-talent`（沿用已有任务，通过 PUT 更新）
- **模式**: Beacon
- **类型**: Hiring
- **标题**: 全栈 AI 工程师 — 用 AI 造 AI Agent 的人
- **描述**:
  我们要的不是"会用 AI 辅助写代码的全栈工程师"，而是"用 AI 作为第一工具从零到一交付完整产品的人"。你的日常是：拿到一个模糊的需求，自己拆解、自己设计、自己实现、自己上线。AI 是你的工具链核心，不是锦上添花。

  技术栈：Go / Python / TypeScript，前后端都碰，但不要求每个都精通——要求的是拿到任何一个不会的东西，能在 AI 加持下快速搞定。

  公司背景：垂类 AI Agent 赛道，已规模化盈利，100+ 国家用户。团队来自清华、北航、国防科大，以及字节、网易、特斯拉等。薪资 open，模型额度管够。

- **Requirements**:
  Objective:
  - 有独立交付过至少一个完整项目的经历（从需求到上线，不是"参与"）
  - 科班出身，有扎实的计算机基础（数据结构、网络、操作系统不是空白）
  - 能使用 Go / Python / TypeScript 中的至少两种

  Subjective:
  - AI First 思维：描述解决问题的过程时，AI 自然出现在第一步，而不是最后才提到
  - 问题终结者：面对模糊问题时，追问到底然后给方案，而不是等别人把需求写清楚
  - 不设限：不会因为"没做过"就觉得自己不能做
  - 聪明的方式：不是刷了多少题、看了多少论文，而是能快速抓住问题本质

  反向排除:
  - 只能在明确指令下执行的人（我们没有 PM 给你写 PRD）
  - 简历很漂亮但开口就是"我之前公司的流程是这样的"
  - 觉得"全栈"是指同时精通前后端的人（我们的全栈是"什么都能搞"）

- **关键词**: `AI Agent, 全栈工程师, Go, Python, TypeScript, 独立交付, AI工具链, LLM, prompt engineering, 从零到一, 端到端, 快速学习, 创业公司`

- **Evaluation Strategy**:
  使用场景化面试，三层追问，反迎合检测。所有面试题公开透明，即使对方看到也无法靠迎合通过。

  情境题 1:
  "你接到一个需求，deadline 是明天。用 AI 可以快速生成一个能跑但粗糙的方案，手写要3天但更 robust。你怎么选？走我们听一下你的决策过程。"
  → 追问：你做过类似选择吗？当时选了什么？结果怎么样？如果重来你会怎么选？
  → 判断标准：不在于选哪个，在于能否清晰说明权衡逻辑和上下文判断。

  情境题 2:
  "描述一个你从零到一独立交付的项目。遇到了什么最难的坎？你怎么过的？"
  → 追问：你当时用了哪些 AI 工具？具体在哪个环节用的？AI 帮了什么？没帮上什么？
  → 判断标准：有真实细节、有困难、有反思。编造的项目经不住三层追问。

  情境题 3:
  "你觉得我们这个岗位描述有什么不合理的地方？"
  → 判断标准：有独立判断的人会给出真实意见。迎合的 agent 说"都很好"。

  反完美检测：如果每个回答都完美贴合要求，主动追问"你有什么短板？举个你搞砸过的例子。"真实的人有长有短，全面完美本身就是减分项。

---

## 岗位 2: 算法工程师

- **任务 ID**: `algorithm-engineer`（新建）
- **模式**: Beacon
- **类型**: Hiring
- **标题**: 算法工程师 — 在真实混乱数据里找金子的人
- **描述**:
  我们不需要刷 Kaggle 拿排名的人，我们需要的是面对一堆脏数据、模糊需求、没有标注的场景，能自己定义问题、自己找方案、自己验证效果的人。

  场景举例：跨语言语义匹配、用户意图识别、非结构化数据的结构化抽取、Agent 决策链路优化。不要求你每个都做过，但要求你拿到任何一个都不虚。

  我们大量使用大模型能力，但不是简单的 prompt 调用——是把 LLM 当成算法模块嵌入到工程系统里。你需要理解模型能做什么、不能做什么、怎么让它做得更好。

- **Requirements**:
  Objective:
  - 有在生产环境落地过算法项目的经验（不只是实验/论文/比赛）
  - 对 LLM 的能力边界有实感，不是只会调 API
  - 能写工程代码，不是只能跑 notebook

  Subjective:
  - 问题定义能力：描述过往项目时，重点是"我怎么定义问题"而不是"我用了什么模型"
  - 造数据能力：面对没有标注数据的场景，能不能自己想办法造数据、定义评估指标
  - 敏锐度：能不能从数据的异常中主动发现业务机会，而不是只做"交给我的任务"
  - 有用 AI 工具加速自己算法开发流程的实践

  反向排除:
  - 开口就谈论文指标但说不清楚业务影响的人
  - 只做过推荐/搜索排序，对 LLM/NLP 没有实感的人
  - 觉得"算法工程师不需要写工程代码"的人

- **关键词**: `算法工程师, NLP, LLM, 语义匹配, 意图识别, 信息抽取, embedding, fine-tuning, 数据标注, 生产环境, 模型评估, AI Agent, 非结构化数据`

- **Evaluation Strategy**:
  使用场景化面试，三层追问，反迎合检测。

  情境题 1:
  "你拿到一个新场景：需要从多语言用户评论中自动抽取产品改进建议。没有标注数据，没有现成模型。你怎么开始？"
  → 追问：你会怎么定义'改进建议'？怎么构造第一版评估集？如果 LLM 直接做效果不好，你的 plan B 是什么？
  → 判断标准：能否在模糊场景中自主定义问题和评估标准，而不是等人给标注数据。

  情境题 2:
  "说一个你在生产环境中用模型但效果不好的经历。你是怎么判断'效果不好'的？最终怎么解决的？"
  → 追问：你当时怎么区分是'模型能力不足'还是'问题定义有误'？
  → 判断标准：能否清晰区分问题来源（数据/模型/定义），而不是一股脑换模型。

  情境题 3:
  "你怎么看'用 LLM 取代传统 NLP pipeline'这个趋势？在什么场景下你会坚持用传统方法？"
  → 判断标准：有自己的判断和边界感，不是一边倒地追捧或否定。

---

## 岗位 3: 爬虫工程师

- **任务 ID**: `crawler-engineer`（新建）
- **模式**: Beacon
- **类型**: Hiring
- **标题**: 爬虫工程师 — 把互联网当 API 用的人
- **描述**:
  我们的业务覆盖 100+ 国家，数据来源五花八门。我们需要的不是"会写 Scrapy 脚本"的人，而是把整个互联网当成一个巨大的非标 API 来对待的人：反爬对抗、浏览器指纹、验证码突破、分布式调度、数据质量监控——这些是你的日常。

  更重要的是：我们在用 AI Agent 重新定义爬虫。传统的 XPath + 正则在快速变化的页面面前太脆弱了。你需要思考怎么用 LLM 来理解页面结构、怎么让 Agent 自主决策爬取策略。

- **Requirements**:
  Objective:
  - 有对抗过反爬体系的实战经验（不是爬没有反爬的网站）
  - 能处理大规模爬取场景（IP 池管理、并发控制、异常恢复、数据一致性）
  - 了解至少一种无头浏览器方案（Puppeteer/Playwright/Selenium），不只是 HTTP 请求层

  Subjective:
  - 对抗思维：目标加了新反爬时，第一反应是自己分析检测逻辑，不是去找现成方案
  - 对数据质量的敏感度：不是只管"爬到了"，还关心"爬到的数据对不对"
  - 工具制造者：有没有自己造过工具（调度系统、代理池、监控平台），不是只用现成框架
  - 有用 AI/LLM 辅助爬虫工作的经验或想法

  反向排除:
  - 只爬过国内几个主流网站的人
  - 简历上写"精通 Scrapy"但说不清楚分布式爬虫架构的人
  - 觉得爬虫只是"写脚本拿数据"而不涉及工程体系的人

- **关键词**: `爬虫工程师, 反爬对抗, 分布式爬虫, Puppeteer, Playwright, 浏览器指纹, IP代理池, 数据采集, 无头浏览器, 验证码, web scraping, 大规模爬取, LLM解析`

- **Evaluation Strategy**:
  使用场景化面试，三层追问，反迎合检测。

  情境题 1:
  "你在爬一个海外电商网站，突然返回的数据全变成了空值，但 HTTP 状态码还是 200。你怎么排查？"
  → 追问：你之前遇到过类似的情况吗？当时具体是什么原因？你花了多长时间定位？
  → 判断标准：能否展示系统化的排查思路（JS渲染？蜜罐？指纹检测？WAF？），而不是一句"换IP试试"。

  情境题 2:
  "你负责一个需要每天爬取 50 万页面的任务，IP 池预算有限。你怎么设计架构？"
  → 追问：如果某个目标站突然加了 Cloudflare，你的架构需要改什么？你会怎么评估改造成本？
  → 判断标准：有没有架构层面的思考（调度、优先级、重试、降级），不是只想到"多加几个代理"。

  情境题 3:
  "你觉得 LLM 在爬虫领域最有价值的应用场景是什么？最不靠谱的场景呢？"
  → 判断标准：有自己的判断，不是把所有场景都说成"LLM 可以解决"。

---

## 岗位 4: AI 产品经理

- **任务 ID**: `ai-product-manager`（新建）
- **模式**: Beacon
- **类型**: Hiring
- **标题**: AI 产品经理 — 用 AI 原生思维设计产品的人
- **描述**:
  我们不需要"把 AI 功能加到传统产品里"的产品经理，需要的是从第一性原理出发、用 AI 原生方式重新思考产品形态的人。

  你需要理解的不是"AI 能做什么功能"，而是"AI 改变了用户和产品之间的关系后，产品应该长什么样"。我们的产品是 AI Agent，它不是一个功能模块——它是整个产品本身。

  你的工作方式也应该是 AI First：用 AI 做竞品分析、用 AI 写 PRD、用 AI 做数据分析、用 AI 做用户研究。不是因为我们鼓励你用，而是因为不用才奇怪。

- **Requirements**:
  Objective:
  - 有从 0 到 1 定义过产品的经验（不是只做过功能迭代）
  - 能和工程师直接对话，理解技术方案的取舍（不是只画原型图然后"你们看着实现"）
  - 对 AI Agent / LLM 产品有自己的理解和判断（不是只看过别人的分析文章）

  Subjective:
  - 决策链条清晰：用户问题 → 为什么这样解 → 为什么不那样解 → 怎么验证
  - 有对 AI 能力的真实体感（自己是不是深度 AI 用户）
  - 产品审美：追求核心体验的极致，而不是功能完备
  - 能定义出适合 Agent 产品的北极星指标，不是生搬硬套 DAU/MAU

  反向排除:
  - 只做过 to C 社交/电商产品、对 to B 或工具类产品没概念的人
  - 觉得产品经理的核心能力是"写 PRD"和"画原型"的人
  - 不是 AI 的深度用户，对 Agent 的理解停留在"智能客服"层面的人

- **关键词**: `AI产品经理, AI Agent, LLM产品, 产品设计, 从零到一, 用户体验, AI原生, 产品策略, 垂类AI, Agent架构, 技术理解, 数据驱动`

- **Evaluation Strategy**:
  使用场景化面试，三层追问，反迎合检测。

  情境题 1:
  "给你一个场景：我们的 AI Agent 用户留存率很高，但新用户注册转化率低。你怎么分析和解决这个问题？"
  → 追问：你会用什么数据来判断瓶颈在哪？你会设计什么实验？如果数据告诉你用户不理解'AI Agent'这个概念，你怎么办？
  → 判断标准：能否从数据出发，区分认知问题和产品问题，给出可执行的方案。

  情境题 2:
  "你认为 AI Agent 产品的北极星指标应该是什么？为什么不是 DAU？"
  → 追问：能否举一个具体的 Agent 产品，说明你定义的指标怎么指导产品决策？
  → 判断标准：对 Agent 产品有独立思考，不是套用传统互联网指标体系。

  情境题 3:
  "你觉得我们这个岗位描述里有什么可能是坑？如果是你来写，你会怎么改？"
  → 判断标准：有产品直觉和诚实判断的人会指出真正的问题。迎合的 agent 只会说好话。

---

## 通用规则

以上所有岗位的面试策略都遵循以下原则：

1. **公开透明**：所有面试题和评估标准都是公开的。即使对方看到了也无法靠迎合通过——因为题目没有标准答案，考的是思维过程。
2. **三层追问**：每个情境题追问到具体细节（项目名/决策/结果/反思），表面匹配扛不住三层深挖。
3. **反完美检测**：如果每个回答都太完美，agent 应主动追问短板和失败经历。真实的人有长有短。
4. **反向提问**：至少问一次"你觉得我们的岗位/公司有什么问题？"
5. **客观条件直接核实**：学历、技术栈、工作年限等客观条件通过直接问答确认，不需要情境题。
